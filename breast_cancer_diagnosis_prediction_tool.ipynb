{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Brief overview of the Wisconsin Breast Cancer Data Set\n",
    "\n",
    "The Wisconsin Breast Cancer dataset, curated by Dr. William H. Wolberg in collaboration with Olvi Mangasarian and Nick Street, esteemed experts in the fields of computational mathematics and machine learning, is a pivotal resource in the realm of data-driven healthcare. This dataset, originating from the University of Wisconsin Hospital in Madison, has garnered widespread recognition for its application in various machine learning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Importance of breast cancer diagnosis and prediction\n",
    "\n",
    "In the United States, a staggering 2.3 million women received the devastating diagnosis of breast cancer, with 685,000 succumbing to this formidable disease. Projections indicate that an additional 297,790 women will face this diagnosis in the current year. However, with early detection and diagnosis, these distressing statistics can see a marked improvement in the years to come.\n",
    "\n",
    "The current methods for detecting and diagnosing breast cancer include biopsies, mammograms, and other established techniques. The incorporation of machine learning-aided predictions introduces a promising new avenue, streamlining the process of providing early intervention and treatment. This addition holds the potential to significantly enhance the effectiveness of early interventions and ultimately improve patient outcomes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II. Background Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Explanation of the Wisconsin Breast Cancer Data Set\n",
    "\n",
    "The Wisconsin Breast Cancer Dataset serves as a widely employed benchmark in the realm of machine learning for discerning the nature of breast cancer tumors, distinguishing between benign and malignant cases. It encapsulates crucial features derived from digitized images of fine needle aspirates (FNA) of breast masses, offering insights into the characteristics of cell nuclei within the images. Notably, this dataset has been pivotal in evaluating the efficacy of various algorithms in diagnosing breast cancer.\n",
    "\n",
    "The process of defining the separating plane was accomplished through the application of the Multisurface Method-Tree (MSM-T), a classification technique introduced by K. P. Bennett. This method leverages linear programming for the construction of a decision tree, providing a robust means of classification. Additionally, the selection of pertinent features involved an exhaustive search within the parameter space encompassing 1 to 4 features and 1 to 3 separating planes.\n",
    "\n",
    "Traditionally, diagnosing breast cancer has entailed a comprehensive biopsy, involving an invasive surgical procedure. However, a less invasive alternative, known as Fine Needle Biopsy (FNB), allows for the examination of a small tissue sample from the tumor. This dataset was curated through the analysis of cell nuclei attributes in 569 images procured via Fine Needle Aspiration of breast masses. Each of these images has been categorized (diagnosed) as either \"Benign\" or \"Malignant\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Description of the attributes and features in dataset\n",
    "\n",
    "The dataset used for diagnosing breast cancer consists of various attributes that provide insights into the characteristics of the tumor. Each sample in the dataset is assigned a unique identification number, which serves as a reference for tracking and identifying individual instances.\n",
    "\n",
    "One of the most critical attributes in the dataset is the diagnosis of the breast cancer tumor, which classifies tumors into two categories: Malignant and Benign. Malignant tumors are cancerous, potentially harmful, and have the potential to spread, while benign tumors are non-cancerous, not harmful, and unlikely to spread.\n",
    "\n",
    "The dataset also includes ten real-valued features computed for each cell nucleus. These features provide valuable information on tumor classification and are computed for each cell nucleus in the sample. The features are as follows:\n",
    "\n",
    "Radius 1 and Radius 2: These attributes represent the average distances from the center of the nucleus to points on its perimeter. They provide information about the size of the nucleus.\n",
    "\n",
    "Texture 1 and Texture 2: These attributes capture the variation in gray-scale values within the nucleus. They reflect the homogeneity or heterogeneity of the cell nucleus.\n",
    "\n",
    "Perimeter 1 and Perimeter 2: These attributes measure the total length of the nucleus's perimeter. They provide information about the shape and boundary of the nucleus.\n",
    "\n",
    "Area 1 and Area 2: These attributes represent the total area enclosed by the nucleus. They provide information about the overall size of the nucleus.\n",
    "\n",
    "Smoothness 1 and Smoothness 2: These attributes quantify the local variations in the lengths of radii. They describe the irregularities or smoothness of the nucleus.\n",
    "\n",
    "Compactness 1 and Compactness 2: These attributes combine information about the perimeter and area to measure the compactness of the nucleus. They help characterize the shape of the nucleus.\n",
    "\n",
    "Concavity 1 and Concavity 2: These attributes describe the severity of concave portions within the contour of the nucleus. They provide insights into irregularities in the nucleus's shape.\n",
    "\n",
    "Concave Points 1 and Concave Points 2: These attributes represent the number of concave portions in the contour of the nucleus. They offer additional details about the shape of the nucleus.\n",
    "\n",
    "Symmetry 1 and Symmetry 2: These attributes measure the symmetry of the nucleus. They assess whether the nucleus exhibits balanced or asymmetrical characteristics.\n",
    "\n",
    "Fractal Dimension 1 and Fractal Dimension 2: These attributes are related to the \"coastline approximation\" of the nucleus. They provide insights into the complexity or irregularity of the nucleus's shape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Significance of the data set in breast cancer research\n",
    "\n",
    "The Breast Cancer Wisconsin dataset is an essential resource in the field of breast cancer research. It contains a comprehensive collection of attributes derived from cell nuclei in breast cancer biopsies, which have been meticulously analyzed and labeled by experts, providing a reliable ground truth for training and testing machine learning models. The dataset also allows for the exploration of less invasive diagnostic techniques like Fine Needle Aspiration (FNA), offering valuable insights into tumor characteristics without resorting to more invasive procedures.\n",
    "\n",
    "Researchers can use this dataset to develop and refine predictive models for diagnosing breast cancer, potentially offering accurate and efficient alternatives to traditional diagnostic methods. The dataset's attributes represent quantifiable characteristics of cell nuclei, providing a basis for feature extraction. This enables the development of algorithms that can automatically identify relevant patterns indicative of malignancy.\n",
    "\n",
    "Moreover, the dataset serves as a standard benchmark for evaluating the performance of machine learning algorithms in breast cancer classification, facilitating the comparison of different techniques and algorithms. Early diagnosis of breast cancer is crucial for successful treatment, and this dataset contributes to the development of tools that can aid in early detection.\n",
    "\n",
    "With over 53 research studies benefiting from this dataset, and even more leveraging its potential, it stands as a testament to its significance in advancing breast cancer research. Overall, the Breast Cancer Wisconsin dataset plays a significant role in advancing our understanding of breast cancer and in developing more effective, efficient, and accessible diagnostic methods for this critical health issue. It empowers researchers and medical professionals to work towards improved outcomes for patients facing breast cancer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "dataset = pd.read_csv('breast_cancer_dataset cs411.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Data cleaning and handling missing values, if applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checks for missing values in the dataset\n",
    "null_values = dataset.isna().sum()\n",
    "\n",
    "print(\"\\n-------Missing Values Check-------\")\n",
    "if null_values.empty:\n",
    "    print(\"These are the null values in the dataset\")\n",
    "\n",
    "    print(\"\\n-------Null Values-------\\n\")\n",
    "    print(null_values)\n",
    "\n",
    "    #deletes rows that have NA values\n",
    "    dataset.dropna()\n",
    "else:\n",
    "    print(\"\\nThere are no missing or unusable values in the dataset\")\n",
    "\n",
    "    print(\"\\n-------Null Values-------\\n\")\n",
    "    print(null_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace M with 1 and Benign with 0 (else 0)\n",
    "\n",
    "dataset[\"diagnosis\"]= dataset[\"diagnosis\"].map(lambda row: 1 if row=='M' else 0)\n",
    "\n",
    "#To check if the column has been transformed\n",
    "#print(\"Legend: Malignant = 1, Benign = 0\")\n",
    "#dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 1:31].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "min_values = np.min(X, axis=0)\n",
    "max_values = np.max(X, axis=0)\n",
    "\n",
    "#Prints min and max values\n",
    "print(\"\\n-------MIN and MAX Values-------\")\n",
    "print(f\"\\nMinimum values:\\n\\n {min_values}\")\n",
    "print(f\"\\nMaximum values:\\n\\n {max_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Exploratory data analysis to understand the distribution of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selects columns to be used in the bar graph\n",
    "selected_mean_columns = dataset.columns[:10]\n",
    "selected_mean_columns = selected_mean_columns.append(pd.Index(['diagnosis']))\n",
    "dataset_mean = dataset[selected_mean_columns]\n",
    "\n",
    "selected_se_columns = dataset.drop(dataset.columns[:10], axis=1)\n",
    "dataset_se = selected_se_columns.drop(selected_se_columns.columns[10:], axis=1)\n",
    "\n",
    "diagnosis_column = dataset['diagnosis']\n",
    "dataset_se = pd.concat([dataset_se,diagnosis_column],axis=1)\n",
    "\n",
    "\n",
    "dataset_worst = dataset.drop(dataset.columns[0:20], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap correlation plot of every feature\n",
    "# columnName = 'diagnosis'\n",
    "# plt.figure(figsize=(25, 15))\n",
    "# plt.hist(columnName,bins=20, edgecolor='black')\n",
    "# plt.title(f'Histogram of {columnName}')\n",
    "# plt.xlabel(columnName)\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show() \n",
    "plt.figure(figsize =(30,30))\n",
    "sns.heatmap(dataset.corr(), vmin=-1, vmax=1, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Feature selection or dimensionality reduction techniques, if needed\n",
    "\n",
    "From heatmap above, we only need to pay attention to the bottom row where the correlation between the diagnosis and the features are seen.\n",
    "\n",
    "We can see that x.fractal_dim_mean, x.texture_se, x.smoothness_se, and x.symmetry_se have negative correlations. Because of this, the said features should be removed given their weak correlations, however we are uncertain whether this will significantly affect the prediction, and so we chose to still include it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IV. Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Descriptive statistics of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive Statistics\n",
    "\n",
    "print(\"\\n-------Number of Rows in dataset-------\\n\")\n",
    "print(dataset.shape[0])\n",
    "\n",
    "print(\"\\n-------Number of Columns in dataset-------\\n\")\n",
    "print(dataset.shape[1])\n",
    "\n",
    "print(\"\\n-------Dataset Head-------\\n\")\n",
    "print(dataset.head())\n",
    "\n",
    "print(\"\\n-------Descriptive Statistics-------\\n\")\n",
    "print(dataset.describe())\n",
    "\n",
    "print(\"\\n-------Number of Data Values-------\\n\")\n",
    "print(dataset.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Visualization of the data to identify patterns and correlations\n",
    "\n",
    "This puts the correlations of each feautre with the diagnosis in bar graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.diagnosis.value_counts() \\\n",
    "    .plot(kind=\"bar\", width=0.1, color=[\"lightgreen\", \"cornflowerblue\"], legend=1, figsize=(8, 5))\n",
    "plt.xlabel(\"(0 = Benign) (1 = Malignant)\", fontsize=12)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend([\"Benign\"], fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph correlation between diagnosis and Mean features\n",
    "plt.figure(figsize=(20, 8))\n",
    "dataset_mean.drop(\"diagnosis\", axis=1).corrwith(dataset_mean.diagnosis).plot(kind='bar', grid=True, title=\"Correlation of Mean Features with Diagnosis\", color=\"cornflowerblue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph correlation between diagnosis and Squared Error features\n",
    "plt.figure(figsize=(20, 8))\n",
    "dataset_se.drop(\"diagnosis\", axis=1).corrwith(dataset_se.diagnosis).plot(kind='bar', grid=True, title=\"Correlation of Squared Error Features with Diagnosis\", color=\"cornflowerblue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph correlation between diagnosis and Worst features\n",
    "plt.figure(figsize=(20, 8))\n",
    "dataset_worst.drop(\"diagnosis\", axis=1).corrwith(dataset_worst.diagnosis).plot(kind='bar', grid=True, title=\"Correlation of Worst Features with Diagnosis\", color=\"cornflowerblue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V. Application of classification algorithms to predict breast cancer diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset into training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X\n",
    "                                                    , y\n",
    "                                                    , test_size = 0.25\n",
    "                                                    , random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0, max_iter=10000)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1)\n",
    "                      , y_test.reshape(len(y_test),1))\n",
    "                      ,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Confusion Matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "class_mapping = {0: 'Benign', 1: 'Malignant'}\n",
    "class_names = dataset['diagnosis'].map(class_mapping).unique()\n",
    "headers = dataset.iloc[:, 1:31].columns.tolist()\n",
    "\n",
    "# Assuming X_train contains all your features\n",
    "sns.pairplot(data=pd.DataFrame(X_train, columns = headers))\n",
    "disp = ConfusionMatrixDisplay.from_estimator(\n",
    "    classifier,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    display_labels=class_names,\n",
    "    cmap=plt.cm.Blues,\n",
    "    normalize='true',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Testing (Expected output = Benign)\n",
    "# user_inputs = np.array([[11.3,18.19,73.93,389.4,0.09592,0.1325,0.1548,0.02854,0.2054,0.07669,0.2428,1.642,2.369,16.39,0.006663,0.05914,0.0888,0.01314,0.01995,0.008675,12.58,27.96,87.16,472.9,0.1347,0.4848,0.7436,0.1218,0.3308,0.1297]])\n",
    "\n",
    "# For Testing (Expected output = Malignant)\n",
    "# user_inputs = np.array([[15.3,25.27,102.4,732.4,0.1082,0.1697,0.1683,0.08751,0.1926,0.0654,0.439,1.012,3.498,43.5,0.005233,0.03057,0.03576,0.01083,0.01768,0.002967,20.27,36.71,149.3,1269,0.1641,0.611,0.6335,0.2024,0.4027,0.09876]])\n",
    "\n",
    "user_inputs = []\n",
    "\n",
    "for class_name, min_val, max_val in zip(headers, min_values, max_values):\n",
    "    while True:\n",
    "        user_input = float(input(f\"Enter {class_name} ({min_val} - {max_val}): \"))\n",
    "        if min_val <= user_input <= max_val:\n",
    "            print(f\"{class_name} input is valid.\")\n",
    "            user_inputs.append(user_input)\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid input. Please enter a value within the specified range.\")\n",
    "    \n",
    "user_inputs = np.array([user_inputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "user_inputs = sc.transform(user_inputs)\n",
    "\n",
    "predicted_result = classifier.predict(user_inputs)\n",
    "predicted_species_probabilities = classifier.predict_proba(user_inputs)\n",
    "\n",
    "predicted_vector = np.zeros(len(class_names))\n",
    "predicted_vector[np.where( dataset['diagnosis'].unique() == predicted_result[0])] = 1\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(class_names, predicted_vector, color=['green' if val else 'red' for val in predicted_vector])\n",
    "plt.xlabel('Classification')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Tumor Predicted Classification')\n",
    "plt.show()\n",
    "\n",
    "print(f\"The predicted classification of tumor: {class_mapping.get(predicted_result[0])}\")\n",
    "print(f\"Accuracy of the model:{(accuracy_score(y_test, classifier.predict(X_test)) * 100):.2f}%\")\n",
    "print(f\"Precision of the model: {(precision_score(y_test, classifier.predict(X_test)) * 100):.2f}%\")\n",
    "print(f\"Recall of the model: {(recall_score(y_test, classifier.predict(X_test)) * 100):.2f}%\")\n",
    "print(f\"F1 Score of the model: {(f1_score(y_test, classifier.predict(X_test)) * 100):.2f}%\")\n",
    "\n",
    "for class_name, probability in zip(class_names, predicted_species_probabilities[0]):\n",
    "    print(f\"Probability of being {class_name}: {(probability * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, ShuffleSplit, cross_val_score \n",
    "\n",
    "# Define the number of splits for cross-validation\n",
    "n_splits = 5\n",
    "\n",
    "# K-Fold\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "kf_scores = cross_val_score(classifier, X, y, cv=kf)\n",
    "print(f\"K-Fold Cross-Validation scores: {kf_scores}\")\n",
    "print(f\"Mean K-Fold Cross-Validation score: {np.mean(kf_scores)}\\n\")\n",
    "\n",
    "# Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "skf_scores = cross_val_score(classifier, X, y, cv=skf)\n",
    "print(f\"Stratified K-Fold Cross-Validation scores: {skf_scores}\")\n",
    "print(f\"Mean Stratified K-Fold Cross-Validation score: {np.mean(skf_scores)}\\n\")\n",
    "\n",
    "# Shuffle Split\n",
    "ss = ShuffleSplit(n_splits=n_splits, test_size=0.25, random_state=0)\n",
    "ss_scores = cross_val_score(classifier, X, y, cv=ss)\n",
    "print(f\"Shuffle Split Cross-Validation scores: {ss_scores}\")\n",
    "print(f\"Mean Shuffle Split Cross-Validation score: {np.mean(ss_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Evaluation metrics for binary classification (e.g., accuracy, precision, recall, F1 score)\n",
    "\n",
    "At test_size 0.25\n",
    "a. Accuracy: 99.3%\n",
    "b. Precision: 100.00%\n",
    "c. Recall: 98.21%\n",
    "d. F1 Score: 99.10%\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Cross-validation techniques to assess model performance.\n",
    "\n",
    "K-Fold Cross-Validation scores: 0.95614035, 0.95614035, 0.92982456, 0.96491228 0.9380531\n",
    "\n",
    "Mean K-Fold Cross-Validation score: 0.9490141282409563\n",
    "\n",
    "Stratified K-Fold Cross-Validation scores: 0.96491228, 0.96491228, 0.94736842, 0.95614035, 0.94690265\n",
    "\n",
    "Mean Stratified K-Fold Cross-Validation score: 0.956047197640118\n",
    "\n",
    "Shuffle Split Cross-Validation scores: 0.96503497, 0.91608392, 0.93706294, 0.96503497, 0.95804196"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Interpretation of Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Analysis of the most influential features in breast cancer prediction\n",
    "\n",
    "According to the correlation heatmap and the correlation graphs, these are the following features with values from 0.6 to 0.8 and therefore have strong correlations with the diagnosis and hence are the most influential when predicting breast cancer.\n",
    "\n",
    "Features with strong correlations (0.6 - 0.8)\n",
    "x.radius_mean = 0.73\n",
    "x.perimeter_mean = 0.74\n",
    "x.area_mean = 0.71\n",
    "x.compactness_mean = 0.6\n",
    "x.concativity_mean = 0.7\n",
    "x.concave_pts_mean = 0.78\n",
    "x.radius_worst = 0.78\n",
    "x.perimeter_worst = 0.78\n",
    "x.area_worst = 0.73\n",
    "x.concavity_worst = 0.66\n",
    "x.concave_pts_worst = 0.79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Insightful findings and observations from the model\n",
    "\n",
    "a. Depending on size of the test and training data, the accuracy, precision, recall, and F1 score of the model changes. We can infer here that larger datasets could lead to more accurate predictions if quality data is presented.\n",
    "\n",
    "b. The evaluation metrics score of the model indicate that the model makes accurate predictions\n",
    "\n",
    "c. The Cross validation scores on each technique are all above 0.9. This indicates that the model is making accurate predictions, can adapt to new data, and is not overfitting data. All-in-all, we can say that the classification model performs well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D. Discussion of the clinical implications and potential applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Limitations and Future Directions\n",
    "\n",
    "The Breast Cancer Wisconsin dataset is an invaluable resource for breast cancer research, but it does come with certain limitations. Firstly, the dataset focuses mainly on cell nuclei characteristics from breast cancer biopsies, and it lacks broader patient data like genetic information, family history, or lifestyle factors. These elements could provide a more comprehensive understanding of breast cancer. Additionally, there may be an imbalance in the distribution between benign and malignant cases, which could affect the performance of certain machine learning algorithms.\n",
    "\n",
    "The dataset only provides attributes from a single point in time, and as such, it offers a static snapshot of cell nuclei characteristics, without accounting for potential changes over time. Furthermore, it includes a specific set of features computed from cell nuclei, potentially overlooking other relevant attributes that could contribute to a more accurate diagnosis.\n",
    "\n",
    "It is essential to understand the origin and collection details of the data, as factors such as biopsy selection criteria, pathologist expertise, and potential biases in data collection can influence the findings. The dataset also lacks important patient information like age and demographic characteristics, which could be significant in understanding how breast cancer manifests in different age groups and populations.\n",
    "\n",
    "While the dataset is substantial with 569 instances, larger datasets may provide more robust and generalizable insights. Additionally, considering temporal factors is critical, as the dataset's information is derived from a specific time period. \n",
    "\n",
    "One primary limitation of logistic regression in identifying breast cancer is the assumption of linearity between the dependent variable and the independent factors. This assumption may not always hold true in complex biological systems, potentially impacting the accuracy of predictions. Researchers should be mindful of this limitation and explore alternative models or feature engineering techniques to address potential non-linearity in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Addressing limitations of the study and the dataset\n",
    "\n",
    "To overcome the limitations of the Breast Cancer Wisconsin dataset, there are several strategies that researchers can employ. Firstly, researchers can integrate additional data sources that encompass a wider range of patient information to augment the dataset's scope. This may involve incorporating genetic profiles, family history records, and lifestyle data to provide a more comprehensive context for breast cancer analysis. Additionally, techniques such as resampling or utilizing advanced machine learning algorithms designed for imbalanced datasets can be used to mitigate potential imbalances in the distribution of benign and malignant cases, thus improving the performance of predictive models.\n",
    "\n",
    "To address the static nature of the dataset, researchers can explore longitudinal studies or incorporate time-dependent features that provide a dynamic representation of cell nuclei characteristics over time. This approach can give a more nuanced understanding of tumor progression and potentially improve the accuracy of predictions. Furthermore, researchers can apply feature engineering techniques to augment the existing set of attributes derived from cell nuclei. This may involve extracting additional meaningful features or exploring advanced imaging analysis techniques to capture a wider spectrum of relevant information.\n",
    "\n",
    "It is crucial for researchers to understand the nuances of data collection. They should thoroughly investigate factors that influence biopsy selection criteria, account for potential biases introduced by pathologist expertise, and implement robust validation procedures. Additionally, supplementing the dataset with demographic details like age and other relevant patient information can provide a more holistic view of how breast cancer manifests across different populations. Careful handling of missing or incomplete data during preprocessing is imperative to ensure the integrity of analyses.\n",
    "\n",
    "While the current dataset is substantial, exploring opportunities to incorporate larger datasets or leveraging data augmentation techniques can further bolster the robustness and generalizability of findings. Additionally, researchers should be aware of temporal considerations, recognizing that medical practices and technology evolve. Validation against more recent data or considering the temporal relevance of findings can enhance the practical applicability of research outcomes.\n",
    "\n",
    "In the case of logistic regression, acknowledging the assumption of linearity between dependent and independent variables is crucial. Researchers should explore alternative models or employ feature engineering methods, such as polynomial regression or incorporating interaction terms, to account for potential non-linearity in the underlying biological processes. This approach can lead to more accurate predictions and a deeper understanding of the complexities of breast cancer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Suggestions for further research and improvements\n",
    "\n",
    "a) An updated version of of the Wisconsin Breast Cancer dataset wherein its size is increased, its data updated with today's data, and new features to predict breast cancer are added could help in making more accurate predictions in the future.\n",
    "\n",
    "b) Different classification models could also be used on the dataset to verify its performance and identify better classification models that can make more accurate predictions.\n",
    "\n",
    "c) The features used in this dataset may be applied and modified to suit other types of cancer.\n",
    "\n",
    "Though, it needs to be noted that experts on the subject should take caution when adding new features to predict breast cancer as it may add layers of complexity that might make the dataset incomprehensible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Possible extensions of the analysis to explore additional aspects.\n",
    "\n",
    "Different classification models can be used simultaneously to explore and analyze their performance side by side.\n",
    "\n",
    "Other features from different types of cancer could also be adapted here to explore if they have strong or weak correlations with breast cancer diagnoses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Summary of the case study\n",
    "\n",
    "\n",
    "The case study made use of a Logistic Regression classification model on the Wisconsin Breast Cancer dataset to predict breast cancer.\n",
    "\n",
    "The case study also found that several features in the dataset that was used to predict breast cancer had strong positive correlations with the diagnosis. \n",
    "\n",
    "These features are:\n",
    "x.radius_mean = 0.73\n",
    "x.perimeter_mean = 0.74\n",
    "x.area_mean = 0.71\n",
    "x.compactness_mean = 0.6\n",
    "x.concativity_mean = 0.7\n",
    "x.concave_pts_mean = 0.78\n",
    "x.radius_worst = 0.78\n",
    "x.perimeter_worst = 0.78\n",
    "x.area_worst = 0.73\n",
    "x.concavity_worst = 0.66\n",
    "x.concave_pts_worst = 0.79\n",
    "\n",
    "While a few had negative correlations with the diagnosis\n",
    "\n",
    "These features are:\n",
    "x.fractal_dim_mean\n",
    "x.texture_se\n",
    "x.smoothness_se\n",
    "x.symmetry_se\n",
    "\n",
    "The features with strong correlations should be adopted in future studies while those with negative correlations could be removed.\n",
    "\n",
    "The evaluation metric scores and the cross validation scores of the model indicate that it is making accurate predictions with little error which indicates that the model performs well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Key takeaways and contributions to the field of breast cancer research\n",
    "\n",
    "According to our research, the Wisconsin Breast Cancer dataset is still widely used today to evaluate the performance of classification models on predicting breast cancer. From this, we can say that Dr. Wolberg and his dataset are the most extremely significant contributors in furthering breast cancer research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UCI Machine Learning Repository. (n.d.). https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic\n",
    "\n",
    "Sumbria, S. (2022, January 8). ⚕️ Breast Cancer Wisconsin [Diagnostic] - EDA  - Analytics Vidhya - Medium. Medium. https://medium.com/analytics-vidhya/breast-cancer-diagnostic-dataset-eda-fa0de80f15bd\n",
    "\n",
    "Karanam, S. (2022, September 30). Exploratory Data Analysis — Breast Cancer Wisconsin (Diagnostic) Dataset. Medium. https://medium.com/@shashmikaranam/exploratory-data-analysis-breast-cancer-wisconsin-diagnostic-dataset-6a3be9525cd\n",
    "\n",
    "Breast Cancer Wisconsin (Diagnostic) data set. (2016, September 25). Kaggle. https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data\n",
    "\n",
    "World Health Organization: WHO & World Health Organization: WHO. (2023, July 12). Breast cancer. https://www.who.int/news-room/fact-sheets/detail/breast-cancer\n",
    "\n",
    "Breast cancer - statistics. (2023, February 23). Cancer.Net. https://www.cancer.net/cancer-types/breast-cancer/statistics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
